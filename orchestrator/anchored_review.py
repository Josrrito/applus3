"""
Anchored Review module for APPLUS3.
GENERATED BY MULTI-IA CONSENSUS (GPT-4o + Claude + DeepSeek)
"""

from dataclasses import dataclass
from typing import List
from knowledge_graph import KnowledgeGraph, Node
from retrieval import ContextRetriever, RetrievalResult

@dataclass
class ReviewScore:
    dimension: str
    score: float
    feedback: str

class AnchoredReviewer:
    def __init__(self, kg: KnowledgeGraph, retriever: ContextRetriever):
        self.kg = kg
        self.retriever = retriever

    def review_code(self, code: str, node_id: str) -> List[ReviewScore]:
        # Retrieve context for the node
        retrieval_result = self.retriever.get_context_for_node(node_id)

        # Build review scores based on code and context
        review_scores = []

        # Review dimensions
        dimensions = [
            ("Code Quality", self._assess_code_quality),
            ("Context Alignment", self._assess_context_alignment),
            ("Dependency Management", self._assess_dependencies)
        ]

        for dimension_name, assessment_func in dimensions:
            score, feedback = assessment_func(code, retrieval_result, node_id)
            review_scores.append(
                ReviewScore(
                    dimension=dimension_name,
                    score=score,
                    feedback=feedback
                )
            )

        return review_scores

    def _assess_code_quality(self, code: str, context: RetrievalResult, node_id: str) -> tuple:
        # Basic code quality heuristics
        score = 0.8
        if len(code.strip()) < 10:
            score -= 0.3
        if "TODO" in code or "FIXME" in code:
            score -= 0.1
        feedback = "Code follows basic structure."
        return score, feedback

    def _assess_context_alignment(self, code: str, context: RetrievalResult, node_id: str) -> tuple:
        # Check consistency with retrieved context
        score = 0.9 if context.relevance > 0.5 else 0.6
        feedback = f"Code alignment with context (relevance: {context.relevance:.2f})."
        return score, feedback

    def _assess_dependencies(self, code: str, context: RetrievalResult, node_id: str) -> tuple:
        # Analyze dependencies based on knowledge graph edges
        node_count = len(context.nodes)
        score = 0.7 if node_count < 3 else 0.9
        feedback = f"Dependencies with {node_count} related components."
        return score, feedback
