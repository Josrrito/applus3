"""
FastAPI entry point for APPLUS3.
GENERATED BY MULTI-IA CONSENSUS (GPT-4o + Claude + DeepSeek)
"""

from __future__ import annotations
import uuid
from typing import Dict, Optional, Any, List
from datetime import datetime

from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel, Field

import sys
sys.path.insert(0, "..")

from orchestrator.orchestrator import Orchestrator, PipelineResult
from orchestrator.knowledge_graph import KnowledgeGraph, NodeType, EdgeType


# Initialize FastAPI app
app = FastAPI(
    title="APPLUS3 API",
    description="Context-Aware Multi-IA Code Generation with Knowledge Graph",
    version="1.0.0"
)

# Initialize components
orchestrator = Orchestrator()

# In-memory storage for job status and results
job_store: Dict[str, Dict[str, Any]] = {}


# Pydantic Models
class GenerateRequest(BaseModel):
    """Request model for generation endpoint."""
    idea: str = Field(..., min_length=1, max_length=2000, description="The idea to process")

    class Config:
        json_schema_extra = {
            "example": {
                "idea": "Create a REST API for user management with authentication"
            }
        }


class GenerateResponse(BaseModel):
    """Response model for generation endpoint."""
    id: str = Field(..., description="Unique identifier for the generation job")
    status: str = Field(..., description="Initial status of the job")
    message: str = Field(..., description="Human-readable message")


class StatusResponse(BaseModel):
    """Response model for job status."""
    id: str = Field(..., description="Unique identifier for the job")
    status: str = Field(..., description="Current status of the job")
    progress: Optional[float] = Field(None, description="Progress percentage")
    current_stage: Optional[str] = Field(None, description="Current pipeline stage")


class ResultResponse(BaseModel):
    """Response model for job result."""
    id: str = Field(..., description="Unique identifier for the job")
    status: str = Field(..., description="Final status of the job")
    result: Optional[Dict[str, Any]] = Field(None, description="Pipeline result")
    error: Optional[str] = Field(None, description="Error message if failed")


class KGStatsResponse(BaseModel):
    """Response model for knowledge graph statistics."""
    total_nodes: int = Field(..., description="Total number of nodes")
    total_edges: int = Field(..., description="Total number of edges")
    node_types: Dict[str, int] = Field(..., description="Distribution of node types")


class KGNodeResponse(BaseModel):
    """Response model for knowledge graph nodes."""
    nodes: List[Dict[str, Any]] = Field(..., description="List of nodes")


class HealthResponse(BaseModel):
    """Response model for health check."""
    status: str = Field(..., description="Overall system status")
    version: str = Field(..., description="API version")


# Background task function
def process_generation(job_id: str, idea: str) -> None:
    """Process generation job in background."""
    try:
        job_store[job_id]["status"] = "processing"
        job_store[job_id]["current_stage"] = "M0"

        # Execute the pipeline
        result = orchestrator.run_pipeline(idea)

        # Store the result
        job_store[job_id].update({
            "status": result.status,
            "result": {
                "pipeline_id": result.pipeline_id,
                "idea": result.idea,
                "m0_result": result.m0_result,
                "m1_result": result.m1_result,
                "m2_result": result.m2_result,
                "validation_scores": [
                    {"dimension": s.dimension, "score": s.score, "feedback": s.feedback}
                    for s in result.validation_scores
                ]
            },
            "error": None,
            "progress": 100.0,
            "current_stage": "completed"
        })

    except Exception as e:
        job_store[job_id].update({
            "status": "failed",
            "result": None,
            "error": str(e),
            "current_stage": "error"
        })


@app.post("/generate", response_model=GenerateResponse, status_code=202)
async def generate_idea(request: GenerateRequest, background_tasks: BackgroundTasks):
    """
    Submit a new idea for processing through the APPLUS3 pipeline.
    Returns a job ID to check status and retrieve results.
    """
    job_id = str(uuid.uuid4())

    job_store[job_id] = {
        "id": job_id,
        "idea": request.idea,
        "status": "accepted",
        "progress": 0.0,
        "current_stage": "queued",
        "result": None,
        "error": None,
        "created_at": datetime.utcnow().isoformat()
    }

    background_tasks.add_task(process_generation, job_id, request.idea)

    return GenerateResponse(
        id=job_id,
        status="accepted",
        message="Pipeline execution started"
    )


@app.get("/status/{id}", response_model=StatusResponse)
async def get_status(id: str):
    """Get the current status of a generation job."""
    if id not in job_store:
        raise HTTPException(status_code=404, detail="Job ID not found")

    job = job_store[id]

    return StatusResponse(
        id=id,
        status=job["status"],
        progress=job.get("progress"),
        current_stage=job.get("current_stage")
    )


@app.get("/result/{id}", response_model=ResultResponse)
async def get_result(id: str):
    """Get the result of a completed generation job."""
    if id not in job_store:
        raise HTTPException(status_code=404, detail="Job ID not found")

    job = job_store[id]

    if job["status"] in ["accepted", "processing"]:
        raise HTTPException(
            status_code=202,
            detail=f"Job is still {job['status']}. Current stage: {job.get('current_stage')}"
        )

    return ResultResponse(
        id=id,
        status=job["status"],
        result=job.get("result"),
        error=job.get("error")
    )


@app.get("/kg/stats", response_model=KGStatsResponse)
async def get_kg_stats():
    """Get knowledge graph statistics."""
    kg = orchestrator.knowledge_graph

    # Count node types
    node_types: Dict[str, int] = {}
    for node in kg.nodes.values():
        type_name = node.node_type.value
        node_types[type_name] = node_types.get(type_name, 0) + 1

    return KGStatsResponse(
        total_nodes=len(kg.nodes),
        total_edges=len(kg.edges),
        node_types=node_types
    )


@app.get("/kg/nodes", response_model=KGNodeResponse)
async def get_kg_nodes():
    """List all nodes in the knowledge graph."""
    kg = orchestrator.knowledge_graph

    nodes = [
        {
            "id": node.id,
            "type": node.node_type.value,
            "content": node.content[:200] + "..." if len(node.content) > 200 else node.content,
            "metadata": node.metadata
        }
        for node in kg.nodes.values()
    ]

    return KGNodeResponse(nodes=nodes)


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint."""
    return HealthResponse(
        status="healthy",
        version="1.0.0"
    )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
